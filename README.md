# Test technique DE Servier

> **Auteur:** Alexandre Bidon
> Data Engineer @ LittleBigCode

- [Test technique DE Servier](#test-technique-de-servier)
  - [Partie 1: Python et Data Engineering](#partie-1-python-et-data-engineering)
    - [Format du r√©sultat JSON](#format-du-r√©sultat-json)
      - [Premi√®re version](#premi√®re-version)
      - [Deuxi√®me version](#deuxi√®me-version)
        - [Exemple](#exemple)
      - [Troisi√®me version (finale)](#troisi√®me-version-finale)
        - [Exemple](#exemple-1)
    - [Stockage des donn√©es](#stockage-des-donn√©es)
    - [Impl√©mentation de la pipeline python](#impl√©mentation-de-la-pipeline-python)
      - [Structure du projet](#structure-du-projet)
    - [Importation des donn√©es](#importation-des-donn√©es)
    - [Nettoyage des donn√©es](#nettoyage-des-donn√©es)
    - [Traitement des donn√©es](#traitement-des-donn√©es)
    - [R√©sultat](#r√©sultat)
  - [Partie 2: SQL](#partie-2-sql)
    - [Premi√®re requ√™te](#premi√®re-requ√™te)
    - [Deuxi√®me requ√™te](#deuxi√®me-requ√™te)

## Partie 1: Python et Data Engineering

### Format du r√©sultat JSON

#### Premi√®re version

Avant de pr√©parer le pipeline de traitement de donn√©es, j'ai d√©fini le format du JSON de sortie. Ma premi√®re version se pr√©sentait de la mani√®re suivante:

```JSON
{
    "name": "graphe m√©dicament servier",
    "date": "date de l'output",
    "nodes": [
        {
            // Le type de la node
            // journal | pubmed | drug | clinical_trial
            "type": "", 
            // Le nom de la node, d√©pend du type de la node
            // Le titre du journal | Le nom de la publication | Le nom du m√©dicament | Le nom de l'essai clinique
            "name": ""
        }
    ],
    "links": [
        {
            "from": "",
            "to": "",
            // La date de la mention
            "date": ""
        }
    ]
}
```

Ce format convient pour l'exercice, il est simple √† mettre en place. Cependant, il comporte de nombreux d√©fauts:

- Le format ne scale pas tr√®s bien avec un grand nombre de nodes et de links
- Les nodes n'ont pas d'identifiant unique, deux nodes pourraient avoir le m√™me nom et elles seraient alors indistinguable.
- La recherche de lien entre plusieurs nodes serait longue et fastidieuse. Il faudrait traverser toute la liste des *links* pour trouver les liens des nodes concern√©es.
- Les liens entre les *Drugs* et les *PubMeds* / *Clinical trials* n'ont pas de date. On m√©lange donc des liens avec des formats diff√©rents. Le format n'est pas robuste et ne scale pas bien.

J'ai donc modifi√© mon format afin de r√©pondre √† ces diff√©rents probl√®mes.

#### Deuxi√®me version

Cet deuxi√®me version a √©t√© concu pour scale avec un plus grand nombre de node et pour faciliter l'idenfication d'une node. Toutes les nodes ont d√©sormais un ID unique. Les liens des nodes sont directements r√©f√©renc√©s dans celle-ci. Il est donc plus facile de naviguer de node en node.

```JSON
{
    "name": "graphe m√©dicament servier",
    "date": "date de l'output",
    "nodes": [
        {
            // Le type de la node
            // journal | pubmed | drug | clinical_trial
            "type": "", 
            // Identifiant de la node
            "id": "",
            // Le nom de la node, d√©pend du type de la node
            // Le titre du journal | Le nom de la publication | Le nom du m√©dicament | Le nom de l'essai clinique
            "label": "",
            //
            "ref": [
                {
                    "id": "L'id de la node",
                    // La date de la mention
                    "date": ""
                }
            ]
        }
    ]
}
```

##### Exemple

Pour illustrer le choix du format, j'ai r√©alis√© un output d'exemple:

```JSON
{
    "name": "graphe m√©dicament servier",
    "date": "01/02/2024",
    "nodes": [
        {
            "type": "journal", 
            "id": "001",
            "label": "Journal of emergency nursing",
            "ref": [
                {
                    "id": "A04AD",
                    "date": "01/01/2019"
                }
            ]
        },
        {
            "type": "pubmed", 
            "id": "002",
            "label": "A 44-year-old man with erythema of the face diphenhydramine, neck, and chest, weakness, and palpitations",
            "ref": [
                {
                    "id": "001",
                    "date": "01/01/2019"
                }
            ]
        },
        {
            "type": "drug", 
            "id": "A04AD",
            "label": "Diphenhydramine",
            "ref": [
                {
                    "id": "002"
                }
            ]
        }
    ]
}
```

Cet exemple peut √™tre repr√©sent√© de la mani√®re suivante:

```mermaid
graph TD;
    classDef journal stroke:#6e440f,fill:#fa991c,color:#000,stroke-width:2px
    classDef pubmed stroke:#135061,fill:#1c768f,color:#000,stroke-width:2px
    classDef drug stroke:#031926,fill:#032539,color:#fff,stroke-width:2px

    journal001("
        <b>ID: 001</b>
        <b>Type:</b> Journal
        <b>Name:</b> Journal of emergency nursing
    "):::journal

    pubmed002("
        ID: 002
        <b>Type:</b> Pubmed
        <b>Name:</b> A 44-year-old man with erythema of the face diphenhydramine,
        neck, and chest, weakness, and palpitations
    "):::pubmed

    drug003("
        <b>ID: A04AD</b>
        <b>Type:</b> Drug
        <b>Name:</b> Diphenhydramine
    "):::drug

    pubmed002 -->|01/01/2019| journal001

    drug003 --> pubmed002

    journal001 -->|01/01/2019| drug003
```

Cette version apporte des am√©liorations par rapport √† la premi√®re, mais il est encore possible de l'am√©liorer.

#### Troisi√®me version (finale)

Pour cette troisi√®me et derni√®re version, l'objectif a √©t√© d'am√©liorer les performances lors du parcours du graphe. Les √©l√®ments ont d√©sormais un ID interne qui diff√®re de l'ID des donn√©es d'origines. Tous les objets ont un attribut "metadata" qui contient les informations sp√©cifiques √† celui-ci. Le format des m√©tadatas d√©pend du type d'objet en entr√©e.

On a alors le format suivant:

```JSON
{
    "name": "graphe m√©dicament servier",
    "date": "date de l'output",
    "nodes": {
        "Internal-ID": {
            // Le type de la node
            // journal | pubmed | drug | clinical_trial
            "type": "", 

            "metadata": {
                // D√©pend du type de la node
            },
            "ref": [
                {
                    "id": "L'id interne de la node",
                    // La date de la mention
                    "date": ""
                }
            ]
        }
    }
}
```

Ici l'attribut "metadata" peut avoir les formats suivants:


**Format "journal"**

```JSON
{
    "title": ""
}
```

---
**Format "pubmed"**

```JSON
{
    "id": "",
    "title": ""
}
```

---
**Format "drug"**

```JSON
{
    "atccode": "",
    "drug": ""
}
```

---
**Format "clinical_trials"**

```JSON
{
    "id":"",
    "scientific_title":""
}
```

---

> [!IMPORTANT]  
> L'ajout d'un identifiant interne peut sembler lourd et superflus. En effet, la plupart des ressources disposent d√©j√† d'un ID dans les donn√©es d'origines.
> 
> Cependant, les formats d'ID sont tous diff√©rents. Rien ne garanti que les sources de donn√©es diff√©rentes ne renvoie un m√™me identifiant pour des objets diff√©rents. Sur un jeu de donn√©es plus gros (en production), la probabilit√© d'une collision serait √©lev√©e et risquerait de casser l'int√©grit√© des donn√©es.
> 
> Je suppose dans notre cas que les identifiants pr√©sents dans les donn√©es d'origines (atccode,id) pourraient √™tre des informations utiles et importantes. Il est donc n√©cessaire de les conserver dans le JSON final. Ils ne seront pas contre pas utilis√©s pour identifier et indexer les objets.

> [!NOTE]
> Le param√®tre metadata permet d'avoir des objets avec des param√®tres diff√©rents. Lorsque l'on arrive sur une node, on peut lire son type pour connaitre le format des metadata. Il sera aussi possible de facilement mettre √† jour ce param√®tre. On pourrait par exemple rajouter des informations sur les journaux √† l'aide de nouveaux param√®tres dans les metadata.

On utilisera ici des UUIDs pour la g√©n√©ration des ID internes. Cela permettra de minimiser tr√®s fortement le risque de collision ([voir cet exemple](https://devina.io/collision-calculator)).

##### Exemple

On reprend l'exemple pr√©c√©dent. Ici, le JSON aurait le format suivant:

```JSON
{
    "name": "graphe m√©dicament servier",
    "date": "01/02/2024",
    "nodes": {
        "00000000-0000-0000-0000-00000000001": {
            "type": "journal", 
            "metadata": {
                "title": "Journal of emergency nursing"
            },
            "ref": [
                {
                    "id": "00000000-0000-0000-0000-00000000003",
                    "date": "01/01/2019"
                }
            ]
        },
        "00000000-0000-0000-0000-00000000002": {
            "type": "pubmed", 
            "metadata": {
                "id": "",
                "title": "A 44-year-old man with erythema of the face diphenhydramine, neck, and chest, weakness, and palpitations"
            },
            "ref": [
                {
                    "id": "00000000-0000-0000-0000-00000000001",
                    "date": "01/01/2019"
                }
            ]
        },
        "00000000-0000-0000-0000-00000000003": {
            "type": "drug", 
            "metadata": {
                "atccode": "A04AD",
                "drug": "Diphenhydramine"
            },
            "ref": [
                {
                    "id": "00000000-0000-0000-0000-00000000002"
                }
            ]
        }
    }
}
```

### Stockage des donn√©es

Les donn√©es du projet sont enregistr√©es dans un dossier avec l'organisation suivante:

```
üìÇ data
‚î£ üìÇ 01_raw
‚î£ üìÇ 02_intermediate
‚îó üìÇ 03_result
```

Le dossier *01_raw* contient les donn√©es brutes telles qu'on les recoit. Dans le cadre d'un projet en production, cela correspondrait √† un **data lake**.

Le dossier *02_intermediate* contient les r√©sultats interm√©diaires. On peut par exemple exporter certaines tables ayant re√ßu un premier traitement.

Enfin le dossier *03_result* contient la donn√©e enti√®rement pr√©par√©e telle qu'elle est demand√©e dans l'√©nonc√©.

### Impl√©mentation de la pipeline python

Afin de coder le pipeline de traitement de donn√©es en python, il faut s√©lectionner un framework adapt√© pour la manipulation de donn√©es. Plusieurs choix sont possibles en Python. J'ai opt√© pour la librairie **pandas**. Cette librairie permet d'importer et de manipuler des dataframes. Ce choix est adapt√© √† la taille des jeux de donn√©es. Cependant, ce choix serait moins pertinent avec une mise en production sur des jeux de donn√©es plus volumineux. Il serait pr√©ferable dans ce cas de figure de choisir un framework comme **Spark**.

#### Structure du projet

Le projet est structur√© de la mani√®re suivante:

```
üì¶ package
‚î£ üìÇ data
‚îÉ ‚îó üìÇ load
‚îÉ ‚îó üìÇ transform
‚îó üìÇ processing
```

Le projet a √©t√© pens√© de mani√®re √† r√©pondre √† plusieurs besoins:

- Le projet est packag√© pour √™tre utilis√© facilement
- Le package est d√©coup√© en sous module pouvant √™tre utilis√© ind√©pendament. Cela permet de r√©utiliser les modules pour d'autres traitements. Il est aussi possible de controler ces modules dans un pipeline √† l'aide d'un outil comme Airflow.

> [!NOTE]
> Dans mon projet, j'ai utilis√© la feature *pipe* de **pandas** pour construire ma pipeline.


> [!NOTE]  
> Le module "data/transform" a √©t√© test√© √† l'aide du framework .

### Importation des donn√©es

Le module d'importation des donn√©es doit r√©pondre √† plusieurs besoins:

- Il doit supporter plusieurs types de donn√©es en entr√©e: CSV et JSON
- Il doit s'assurer de l'int√©grit√© des donn√©es en entr√©e (virgule en trop dans le JSON par exemple)
- Il doit retourner toutes les donn√©es sous forme de dataframes

### Nettoyage des donn√©es

Avant de pouvoir travailler sur les donn√©es afin de construire le JSON de sortie, on doit s'assurer que les donn√©es soient propres. Pour cela, j'ai identifi√© les points suivants:

- Certains string pr√©sentent des artefacts du au format UTF-8. Il faudrait nettoyer les chaines de caract√®res pour les retirer.
- Les donn√©es pr√©sentes des valeurs manquantes, il faudrait id√©alement inf√©rer les valeurs manquantes (id) ou les remplacer par des NA

Lorsque les donn√©es seront propres, une derni√®re √©tape du nettoyage pourra consister √† proprement typer les colonnes.

### Traitement des donn√©es


### R√©sultat

## Partie 2: SQL

### Premi√®re requ√™te

Cette premi√®re requ√™te SQL doit permettre de trouver le chiffre d‚Äôaffaires jour par jour, du 1er janvier 2019 au 31 d√©cembre 2019.

On travaille sur la table *TRANSACTION* qui contient toutes les ventes et leur montant.

```sql
SELECT date,
       SUM(prod_price * prod_qty) AS  ventes 
FROM TRANSACTION 
WHERE date>='01/01/19' and date<='31/12/19' 
GROUP BY date;
```

On multiplie les colonnes *prod_price* et *prod_qty* pour obtenir le montant total d'une commande. On additionne ensuite le r√©sultat pour obtenir le chiffre d'affaires total (**SUM**) d'une journ√©e (**GROUP BY**). On cadre la requ√™te sur la p√©riode du 1er janvier 2019 au 31 d√©cembre 2019 √† l'aide du **WHERE date>="01/01/19" and date<="31/12/19"**.

### Deuxi√®me requ√™te

Cette deuxi√®me requ√™te doit permettre de d√©terminer, par client et sur la p√©riode allant du 1er janvier 2019 au 31 d√©cembre 2019, les ventes meuble et d√©co r√©alis√©es.

```sql
SELECT client_id, 
       SUM(CASE WHEN product_type = 'MEUBLE' THEN prod_price * prod_qty ELSE 0 END) AS ventes_meuble,
       SUM(CASE WHEN product_type = 'DECO' THEN prod_price * prod_qty ELSE 0 END) AS ventes_deco
FROM TRANSACTION
INNER JOIN PRODUCT_NOMENCLATURE ON TRANSACTION.prod_id = PRODUCT_NOMENCLATURE.product_id
WHERE date>='01/01/19' and date<='31/12/19' 
GROUP BY client_id;
```

On utilise des sommes avec conditions (**CASE**) pour s√©parer les montants d√©co et meuble. On r√©alise une jointure sur les deux tables pour obtenir toutes les informations n√©cessaires sur les commandes. On regroupe enfin par les montants par client (client_id).

> [!WARNING]  
> J'ai d√©cid√© ici de r√©aliser un INNER JOIN pour join les deux tables. Si un produit dans une commande n'est pas r√©f√©renc√© dans la table des nomenclatures, il ne sera pas compt√© dans le r√©sultat final.
>
> Je consid√®re dans cette requ√™te que les donn√©es ont √©t√© nettoy√©es et pr√©par√©es en amont. Des tests ont donc permis de v√©rifier que tous les produits √©taient bien r√©f√©renc√©s. Il possible de tester ce genre de donn√©es √† l'aide d'outils comme DBT par exemple.
